version: '3'

services:
# ----------------------------- Nginx ----------------------------- #
  web:
    image: nginx
    volumes:
    - "nginx_data:/data"
    ports:
    - "8080:80"
    environment:
    - NGINX_HOST=localnetwork.com
    - NGINX_PORT=80



# ----------------------------- MySQL ----------------------------- #
  mysql:
    image: mysql
    restart: always
    container_name: mysql
    networks:
      - "dev_networks"
    environment:
      MYSQL_ROOT_PASSWORD: 'root'
      MYSQL_DATABASE: 'test'
    command: ['mysqld']
    ports:
      - "3306:3306"
    volumes:
      - "mysql_data:/data"
    tty: true
    # Get the process id of mysql: netstat -vanp tcp | grep 3306
    # Kill mysql: kill P_ID
    # CONNECT TO DB FROM TERMINAL: mysql -u root -proot -h localhost test
    # Lodad data to db:     mysql -u root -p -h 127.0.0.1 test < /Users/ricky/Downloads/test.sql

  mysql-workbench:
    image: lscr.io/linuxserver/mysql-workbench:latest
    container_name: mysql-workbench
    networks:
      - "dev_networks"
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/London
    volumes:
      - "mysql_workbench_data:/data"
    ports:
      - 3000:3000
    cap_add:
      - IPC_LOCK
    depends_on:
      - mysql



# ----------------------------- MongoDB ----------------------------- #
  mongo:
    image: mongo
    restart: always
    container_name: mongo
    networks:
      - "dev_networks"
    ports:
      - "27017:27017"
    volumes:
      - "mongo_data:/data"
    # environment:
      # MONGO_INITDB_ROOT_USERNAME: 'root'
      # MONGO_INITDB_ROOT_PASSWORD: 'root'
    # Load data to MongoDB: mongorestore 'mongodb://127.0.0.1:27017/test' /Users/ricky/Downloads/test

  mongo-express:
    image: mongo-express
    restart: always
    ports:
      - 3001:3001
    environment:
      # ME_CONFIG_MONGODB_ADMINUSERNAME: root
      # ME_CONFIG_MONGODB_ADMINPASSWORD: root
      # ME_CONFIG_MONGODB_URL: mongodb://root:root@mongo:27017/
      ME_CONFIG_MONGODB_URL: mongodb://localhost:27017/
    depends_on:
      - mongo




# ----------------------------- Reids ----------------------------- #
  redis:
    image: redis
    restart: always
    container_name: redis
    networks:
      - "dev_networks"
    ports:
      - "6379:6379"
    volumes:
      - "redis_data:/data"
    tty: true
  
  redis-commander:
    container_name: redis-commander
    hostname: redis-commander
    image: rediscommander/redis-commander:latest
    networks:
      - "dev_networks"
    ports:
      - "9002:9002"
    environment:
      - REDIS_HOSTS=local:redis:6379
    depends_on:
      - redis



# ----------------------------- ElastcSearch ----------------------------- #
  elasticsearch:
    image: elasticsearch:7.17.5
    restart: always
    container_name: elasticsearch
    networks:
      - "dev_networks"
    ports:
      - "9200:9200"
    volumes:
      - "elasticsearch_data:/data"
    environment:
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - discovery.type=single-node
      # Open: http://127.0.0.1:9200/

  kibana:
    image: kibana:7.17.5
    container_name: kibana
    networks:
      - "dev_networks"
    ports:
      - "5601:5601"
    volumes:
      - "kibana_data:/data"
    depends_on:
      - elasticsearch
      # Open: http://localhost:5601



# ----------------------------- RabbitMQ ----------------------------- #
  rabbit_mq:
    image: "bitnami/rabbitmq"
    restart: always
    container_name: rabbit_mq
    networks:
      - "dev_networks"
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - "rabbitmq_data:/data"
    environment:
      RABBITMQ_USERNAME: 'user'
      RABBITMQ_PASSWORD: 'password'
      # Open: http://localhost:15672 | username: user | password: password



# ----------------------------- Kafka ----------------------------- #
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    restart: always
    networks:
      - "dev_networks"
    ports:
      - "2181:2181"
    volumes:
      - "zookeeper_data:/data"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
  
  kafka:
    image: docker.io/bitnami/kafka:3.2
    restart: always
    networks:
      - "dev_networks"
    ports:
      - "9092:9092"
    volumes:
      - "kafka_data:/data"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    networks:
      - "dev_networks"
    ports:
      - "9001:9001"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=localhost:2181
    depends_on:
      - zookeeper
      - kafka



volumes:
  nginx_data:
    driver: local
  mysql_data:
    driver: local
  mysql_workbench_data:
    driver: local
  redis_data:
    driver: local
  mongo_data:
    driver: local
  mongoui_data:
    driver: local
  elasticsearch_data:
    driver: local
  kibana_data:
    driver: local
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
  rabbitmq_data:
    driver: local



networks:
  dev_networks:
    # driver: bridge


######################### Commands to run the docker compose file #########################
# docker-compose up
# or
# docker-compose up -d
# or
# docker-compose -f file_name up
# or
# docker-compose -f file_name up -d